{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "# 필요한 import문\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "\n",
    "batch_size = 1\n",
    "input_SequenceLength = 5\n",
    "x = torch.randn(input_SequenceLength, batch_size, 3, 224, 224, requires_grad=True)\n",
    "# x = torch.randn(3, 224, 224, requires_grad=True)\n",
    "onnx_model = onnx.load(\"KSLmodel_resnet50.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\"KSLmodel_resnet50.onnx\")\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# ONNX 런타임에서 계산된 결과값\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "# print(ort_inputs.values())\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# # ONNX 런타임과 PyTorch에서 연산된 결과값 비교\n",
    "# print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([4, 1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "img = Image.open(\"/opt/project/cat_224x224.jpg\")\n",
    "\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "\n",
    "img_ycbcr = img.convert('YCbCr')\n",
    "img_y, img_cb, img_cr = img_ycbcr.split()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "img_y = to_tensor(img)\n",
    "img_y.unsqueeze_(0)\n",
    "print(img_y.shape)\n",
    "img = torch.stack([img_y,img_y], dim=0)\n",
    "img = torch.cat([img,img], dim=0)\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0225473  0.11896955 0.08581965 0.08800738 0.07835913 0.15181457\n",
      "  0.16795596 0.07015321 0.21637318]]\n"
     ]
    }
   ],
   "source": [
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "img_out_y = ort_outs[0]\n",
    "print(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
    "\n",
    "# # PyTorch 버전의 후처리 과정 코드를 이용해 결과 이미지 만들기\n",
    "# final_img = Image.merge(\n",
    "#     \"YCbCr\", [\n",
    "#         img_out_y,\n",
    "#         img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
    "#         img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
    "#     ]).convert(\"RGB\")\n",
    "\n",
    "# # 이미지를 저장하고 모바일 기기에서의 결과 이미지와 비교하기\n",
    "# final_img.save(\"/home/khs/Documents/final_proj/cat_224x224_2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec # trtexec --onnx=./KSLmodel_resnet50.onnx --saveEngine=KSLmodel_resnet50.trt --explicitBatch --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
      "[11/27/2023-14:34:52] [I] === Model Options ===\n",
      "[11/27/2023-14:34:52] [I] Format: ONNX\n",
      "[11/27/2023-14:34:52] [I] Model: ./KSLmodel_resnet50.onnx\n",
      "[11/27/2023-14:34:52] [I] Output:\n",
      "[11/27/2023-14:34:52] [I] === Build Options ===\n",
      "[11/27/2023-14:34:52] [I] Max batch: explicit\n",
      "[11/27/2023-14:34:52] [I] Workspace: 16 MiB\n",
      "[11/27/2023-14:34:52] [I] minTiming: 1\n",
      "[11/27/2023-14:34:52] [I] avgTiming: 8\n",
      "[11/27/2023-14:34:52] [I] Precision: FP32+FP16\n",
      "[11/27/2023-14:34:52] [I] Calibration: \n",
      "[11/27/2023-14:34:52] [I] Refit: Disabled\n",
      "[11/27/2023-14:34:52] [I] Safe mode: Disabled\n",
      "[11/27/2023-14:34:52] [I] Save engine: KSLmodel_resnet50.trt\n",
      "[11/27/2023-14:34:52] [I] Load engine: \n",
      "[11/27/2023-14:34:52] [I] Builder Cache: Enabled\n",
      "[11/27/2023-14:34:52] [I] NVTX verbosity: 0\n",
      "[11/27/2023-14:34:52] [I] Tactic sources: Using default tactic sources\n",
      "[11/27/2023-14:34:52] [I] Input(s): fp16:chw\n",
      "[11/27/2023-14:34:52] [I] Output(s): fp16:chw\n",
      "[11/27/2023-14:34:52] [I] Input build shapes: model\n",
      "[11/27/2023-14:34:52] [I] Input calibration shapes: model\n",
      "[11/27/2023-14:34:52] [I] === System Options ===\n",
      "[11/27/2023-14:34:52] [I] Device: 0\n",
      "[11/27/2023-14:34:52] [I] DLACore: \n",
      "[11/27/2023-14:34:52] [I] Plugins:\n",
      "[11/27/2023-14:34:52] [I] === Inference Options ===\n",
      "[11/27/2023-14:34:52] [I] Batch: Explicit\n",
      "[11/27/2023-14:34:52] [I] Input inference shapes: model\n",
      "[11/27/2023-14:34:52] [I] Iterations: 10\n",
      "[11/27/2023-14:34:52] [I] Duration: 3s (+ 200ms warm up)\n",
      "[11/27/2023-14:34:52] [I] Sleep time: 0ms\n",
      "[11/27/2023-14:34:52] [I] Streams: 1\n",
      "[11/27/2023-14:34:52] [I] ExposeDMA: Disabled\n",
      "[11/27/2023-14:34:52] [I] Data transfers: Enabled\n",
      "[11/27/2023-14:34:52] [I] Spin-wait: Disabled\n",
      "[11/27/2023-14:34:52] [I] Multithreading: Disabled\n",
      "[11/27/2023-14:34:52] [I] CUDA Graph: Disabled\n",
      "[11/27/2023-14:34:52] [I] Separate profiling: Disabled\n",
      "[11/27/2023-14:34:52] [I] Skip inference: Disabled\n",
      "[11/27/2023-14:34:52] [I] Inputs:\n",
      "[11/27/2023-14:34:52] [I] === Reporting Options ===\n",
      "[11/27/2023-14:34:52] [I] Verbose: Disabled\n",
      "[11/27/2023-14:34:52] [I] Averages: 10 inferences\n",
      "[11/27/2023-14:34:52] [I] Percentile: 99\n",
      "[11/27/2023-14:34:52] [I] Dump refittable layers:Disabled\n",
      "[11/27/2023-14:34:52] [I] Dump output: Disabled\n",
      "[11/27/2023-14:34:52] [I] Profile: Disabled\n",
      "[11/27/2023-14:34:52] [I] Export timing to JSON file: \n",
      "[11/27/2023-14:34:52] [I] Export output to JSON file: \n",
      "[11/27/2023-14:34:52] [I] Export profile to JSON file: \n",
      "[11/27/2023-14:34:52] [I] \n",
      "[11/27/2023-14:34:52] [I] === Device Information ===\n",
      "[11/27/2023-14:34:52] [I] Selected Device: NVIDIA GeForce RTX 3060\n",
      "[11/27/2023-14:34:52] [I] Compute Capability: 8.6\n",
      "[11/27/2023-14:34:52] [I] SMs: 28\n",
      "[11/27/2023-14:34:52] [I] Compute Clock Rate: 1.777 GHz\n",
      "[11/27/2023-14:34:52] [I] Device Global Memory: 12036 MiB\n",
      "[11/27/2023-14:34:52] [I] Shared Memory per SM: 100 KiB\n",
      "[11/27/2023-14:34:52] [I] Memory Bus Width: 192 bits (ECC disabled)\n",
      "[11/27/2023-14:34:52] [I] Memory Clock Rate: 7.501 GHz\n",
      "[11/27/2023-14:34:52] [I] \n",
      "[11/27/2023-14:34:57] [I] [TRT] ----------------------------------------------------------------\n",
      "[11/27/2023-14:34:57] [I] [TRT] Input filename:   ./KSLmodel_resnet50.onnx\n",
      "[11/27/2023-14:34:57] [I] [TRT] ONNX IR version:  0.0.7\n",
      "[11/27/2023-14:34:57] [I] [TRT] Opset version:    8\n",
      "[11/27/2023-14:34:57] [I] [TRT] Producer name:    MATLAB Deep Learning Toolbox Converter for ONNX Model Format\n",
      "[11/27/2023-14:34:57] [I] [TRT] Producer version: 21.2.0\n",
      "[11/27/2023-14:34:57] [I] [TRT] Domain:           \n",
      "[11/27/2023-14:34:57] [I] [TRT] Model version:    0\n",
      "[11/27/2023-14:34:57] [I] [TRT] Doc string:       \n",
      "[11/27/2023-14:34:57] [I] [TRT] ----------------------------------------------------------------\n",
      "[11/27/2023-14:34:57] [W] [TRT] /home/jenkins/agent/workspace/OSS/OSS_L0_MergeRequest/oss/parsers/onnx/onnx2trt_utils.cpp:271: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.\n",
      "ERROR: Graph contains a cycle\n",
      "[11/27/2023-14:34:57] [E] [TRT] /home/jenkins/agent/workspace/OSS/OSS_L0_MergeRequest/oss/parsers/onnx/ModelImporter.cpp:690: ERROR: /home/jenkins/agent/workspace/OSS/OSS_L0_MergeRequest/oss/parsers/onnx/ModelImporter.cpp:79 In function parseGraph:\n",
      "[5] Assertion failed: toposort(graph.node(), &topoOrder)\n",
      "[11/27/2023-14:34:57] [E] Failed to parse onnx file\n",
      "[11/27/2023-14:34:57] [E] Parsing model failed\n",
      "[11/27/2023-14:34:57] [E] Engine creation failed\n",
      "[11/27/2023-14:34:57] [E] Engine set up failed\n",
      "&&&& FAILED TensorRT.trtexec # trtexec --onnx=./KSLmodel_resnet50.onnx --saveEngine=KSLmodel_resnet50.trt --explicitBatch --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=./KSLmodel_resnet50.onnx --saveEngine=KSLmodel_resnet50.trt  --explicitBatch --inputIOFormats=fp16:chw --outputIOFormats=fp16:chw --fp16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
